---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about-zh.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# <span style="color:rgb(17,85,160)">ä¸ªäººç®€ä»‹</span>
<!--  
# Biography
# ğŸ‘¦ Biography
-->

å´ç§‘å›ï¼Œåšå£«ï¼ŒIEEEé«˜çº§ä¼šå‘˜ï¼Œç°ä»»åä¸­ç§‘æŠ€å¤§å­¦ç”µå­ä¿¡æ¯ä¸é€šä¿¡å­¦é™¢è®²å¸ˆ/åŠ©ç†æ•™æˆã€‚åœ¨æ­¤ä¹‹å‰ï¼Œä»–åœ¨æ–°åŠ å¡å—æ´‹ç†å·¥å¤§å­¦ç”µæ°”ç”µå­å·¥ç¨‹å­¦é™¢ä»äº‹åšå£«åç ”ç©¶ï¼ˆä¸Yap Kim-Huiã€å‘¨ç«‹åŸ¹(IEEE Fellow)æ•™æˆï¼‰ã€‚ä»–è·å¾—äº†åä¸­ç§‘æŠ€å¤§å­¦åšå£«å­¦ä½ï¼ˆå¯¼å¸ˆ æ¨é“€ æ•™æˆï¼‰ã€å“ˆå°”æ»¨å·¥ç¨‹å¤§å­¦ç¡•å£«å­¦ä½ï¼ˆå¯¼å¸ˆ è”¡æˆæ¶› æ•™æˆï¼‰å’Œä¸Šæµ·å¤§å­¦å­¦å£«å­¦ä½ã€‚ä»–çš„ç ”ç©¶å…´è¶£åŒ…æ‹¬å¤šæ¨¡æ€å¤§æ¨¡å‹ã€ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ã€é«˜ç»´è§†è§‰å’Œè§†é¢‘å‹ç¼©ä¸ç†è§£ç­‰ï¼Œè¿‘5å¹´åœ¨IEEE T-MMã€IEEE T-CSVTã€NeurIPSã€ACM Multimediaç­‰é«˜æ°´å¹³æœŸåˆŠã€ä¼šè®®å‘è¡¨è®ºæ–‡50ä½™ç¯‡ã€‚ä»–æ‹…ä»»IEEE OJSPã€ASOCã€JRTIPã€JVCIç­‰æƒå¨æœŸåˆŠçš„å‰¯ä¸»ç¼–/ç¼–å§”/å®¢åº§ç¼–è¾‘ç­‰ï¼Œå¹¶åœ¨å›½é™…ä¼šè®®AAAI 2026ã€AIGC 2025ã€IJCNN 2025ã€IEEE ICASSP2024ã€ISCAS2024å’ŒMMSP2023ä¸­æ‹…ä»»ç¨‹åºå§”å‘˜ä¼š/é¢†åŸŸä¸»å¸­/ä¸“é¢˜ä¸»å¸­ç­‰ã€‚<br>
 

ğŸš€ &nbsp; æ‹›æ”¶å…´è¶£ä»äº‹ä»¥ä¸Šç ”ç©¶é¢†åŸŸçš„å®ä¹ ç”Ÿ/è®¿é—®å­¦ç”Ÿ/ç ”ç©¶ç”Ÿ, æ¬¢è¿çº¿ä¸‹æˆ–è¿œç¨‹å®ä¹ /å­¦ä¹ ï¼Œæä¾›è®¡ç®—èµ„æºå’Œæ´¥è´´ã€‚

 

<span class='anchor' id='-professional-activities'></span>
# <span style="color:rgb(17,85,160)">ä¸“ä¸šæ´»åŠ¨</span>
<!-- 
# Professional Activities 
# ğŸ“¢ Professional Services
--> 

<details> 
  <summary>
    <font size=3 color=red>ç®€ä½“ä¸­æ–‡</font>
  </summary>

<div style="height: 400px; overflow-y: auto; border: 1px solid #ccc;">
  <ul>
    <li>ç¼–å§”, å›½é™…æœŸåˆŠApplied Soft Computing (JCR Q1åŒº) </li>  
    <li>å‰¯ä¸»ç¼–, å›½é™…æœŸåˆŠIEEE Open Journal of Signal Processing </li>  
    <li>å®¢åº§ç¼–è¾‘, å›½é™…æœŸåˆŠJournal of Real-Time Image Processing (JCR Q2åŒº) </li>  
    <li>å®¢åº§ç¼–è¾‘, å›½é™…æœŸåˆŠJournal of Visual Communication and Image Representation (JCR Q2åŒº) </li>  
    <li>ç¨‹åºå§”å‘˜ä¼š, å›½é™…ä¼šè®®AAAI 2026, æ–°åŠ å¡ </li>  
    <li>ç¨‹åºå§”å‘˜ä¼š, å›½é™…ä¼šè®®AIGC 2025, æ­å· </li>
    <li>é¢†åŸŸä¸»å¸­, å›½é™…ä¼šè®®IJCNN 2025, æ„å¤§åˆ© </li>  
    <li>ä¸“é¢˜ä¸»å¸­, å›½é™…ä¼šè®®ISCAS 2024, æ–°åŠ å¡ </li>  
    <li>ä¸“é¢˜ä¸»å¸­, å›½é™…ä¼šè®®ICASSP 2024, éŸ©å›½ </li>
    <li>ä¸“é¢˜ä¸»å¸­, å›½é™…ä¼šè®®MMSP2023, æ³•å›½ </li>  
    <li>åº”æ€¥æ€åŠ¿æ„ŸçŸ¥ä¸åº”æ€¥é€šä¿¡æŠ€æœ¯å†³ç­–å’¨è¯¢ä¸“å®¶å›¢é˜Ÿæˆå‘˜, ä¸­å›½ç§‘å </li>
    <li>UWAæŠ€æœ¯è§„åˆ’ç»„ä¸“å®¶, ä¸–ç•Œè¶…é«˜æ¸…è§†é¢‘äº§ä¸šè”ç›ŸUWA </li>  
    <li>Technical Committee Affiliate, Image, Video, and Multidimensional Signal Processing (IVMSP), IEEE ä¿¡å·å¤„ç†å­¦ä¼š </li>
    <li>Technical Committee Affiliate, Multimedia Signal Processing (MMSP), IEEE ä¿¡å·å¤„ç†å­¦ä¼š </li>  
    <li>å®¡ç¨¿äººï¼šIEEE TMM, IEEE TCSVT, IEEE TBc, Pattern Recognition, Information Fusion, NeurIPS, AAAI, ICASSP, etc. </li>    
  </ul>
</div>

</details><br> 

 

<span class='anchor' id='news'></span>
# <span style="color:rgb(17,85,160)">News</span>
<!-- 
# News 
[//]: # ğŸ”¥ News   
-->

<div style="height: 400px; overflow-y: auto; border: 1px solid #ccc;">
  <ul>
    <li>2025.08:&thinsp; Serve as Program Committee in AAAI 2026 conference, Singapore </li>  
    <li>2025.07:&thinsp; Invited to lecture (in English) the 2025 Discover At HUST--"Metavers" International Summer School </li>    
    <li>2025.07:&thinsp; 2 papers are accepted by 33rd ACM International Conference on Multimedia (ACM Multimedia 2025), Dublin, Ireland </li>
    <li>2024.06:&thinsp; Research on Gen-AI based image restoration is Under Revision at IEEE TPAMI</li>
    <li>2025.06:&thinsp; 1 paper is accepted by IEEE Transactions on Multimedia (Corresponding Author)</li>
    <li>2025.06:&thinsp; Serve as Program Committee for International Conference on AI-Generated Content (AIGC 2025), Hangzhou</li>    
    <li>2024.12:&thinsp; 1 paper is accepted by ACM Transactions on Multim. Comput. Commun. Appl. (JCR Q1)</li>
    <li>2024.11:&thinsp; 2 papers are accepted by IEEE Transactions on Multimedia (ä¸­ç§‘é™¢ä¸€åŒºTOPï¼ŒJCR Q1)</li>
    <li>2024.08:&thinsp; 1 paper is accepted by Computer Vision and Image Understanding(JCR Q1)</li>
    <li>2024.05:&thinsp; I am appointed as Special Session Chair by IEEE ISCAS 2024, Singapore</li>
    <li>2024.04:&thinsp; I am appointed as Special Session Chair by IEEE ICASSP 2024, Korea</li>
    <li>2024.01:&thinsp; 2 papers are accepted by Optics Express and Optics Letters</li>
    <li>2023.12:&thinsp; I am awarded the å…¨å›½é‡‘å¥– in ä¸­å›½å›½é™…å¤§å­¦ç”Ÿåˆ›æ–°å¤§èµ›</li>
    <li>2023.11:&thinsp; I am awarded the å…¨å›½é“œå¥– in ä¸­å›½åšå£«ååˆ›æ–°åˆ›ä¸šå¤§èµ›</li>
    <li>2023.10:&thinsp; I am awarded the ä¼˜èƒœå¥– in æ˜¥æ™–æ¯ä¸­å›½ç•™å­¦äººå‘˜åˆ›æ–°åˆ›ä¸šå¤§èµ›</li>
    <li>2023.09:&thinsp; I am appointed as Special Session Chair by IEEE MMSP 2023, France</li>
    <li>2023.09:&thinsp; 1 paper has been accepted by NeurIPS 2023, New Orleans, USA</li>
  </ul>
</div>



<span class='anchor' id='publications'></span>
# <span style="color:rgb(17,85,160)">Selected Publications</span>
<!-- 
# Selected Publications 
[//]: # ğŸ“ Selected Publications 
-->

<!-- æ®µè½æ³¨é‡Š 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>
-->

[//]: - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**



<div style="height: 400px; overflow-y: auto; border: 1px solid #ccc;">
  <ul>
    
<!-- æ®µè½æ³¨é‡Š 
    <li>&thinsp;Tianyi Liu, <b>Kejun Wu</b>, Yi Wang, Wenyang Liu, Kim-Hui Yap, Lap-Pui Chau, "BitsCV: Restoration of Artifacts Decoded in Bitstream-Corrupted Videos," in <b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b></li>
    <li>&thinsp;Wenyang Liu, Tianyi Liu, Chen Cai, Jianjun Gao, Kejun Wu, Kim-Hui Yap, "AsTaSR: Adaptive Superpixel Token Aggregation for Lightweight Image Super-Resolution,"
-->

  <li>&thinsp;T. Liu, <b>K. Wu</b>, C. Cai, Y. Wang, K. Yap, L. Chau, "Towards Blind Bitstream-corrupted Video Recovery: A Visual Foundation Model-driven Framework," in <b>ACM MM 2025</b></li>
  <li>&thinsp;C. Cai, T. Liu, J. Gao, W. Liu, <b>K. Wu</b><font color=Blue>*</font>, R. Wang, Y. Wang, S. Liew, "From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Grounded Situation Recognition," in <b>ACM MM 2025</b> (Corresponding Author) </li>    
  <li>&thinsp;<b>K. Wu</b>, Z. Li, Y. Yang, Q. Liu, and X. Zhang, â€œEnd-to-end Deep Video Compression Based on Hierarchical Temporal Context Learning,â€ in <b>IEEE Transactions on Multimedia</b>, 2025.</li>
  <li>&thinsp;W. Liu, C. Cai, J. Gao, <b>K. Wu</b><font color=Blue>*</font>, Y. Wang, K. Yap, and L. Chau, â€œPromptSR: Cascade Prompting for Lightweight Image Super-Resolution,â€ in <b>IEEE Transactions on Multimedia</b>, 2025. (Corresponding Author)</li>
  <li>&thinsp;<b>K. Wu</b>, Y. Yang, G. Jiang, and X. Zhang, â€œHierarchical Independent Coding Scheme for Varifocal Multiview Images based on Angular-focal Joint Prediction,â€ <b>IEEE Transactions on Multimedia</b>, 26:2993-3006, 2024. $\color{Tomato} {ESI &thinsp;Highly &thinsp;Cited &thinsp;Papers}$</li>
  <li>&thinsp;W. Liu, <b>K. Wu</b><font color=Blue>*</font>, T. Liu, Y. Wang, K. Yap, and L. Chau, â€œByteNet: Rethinking Multimedia File Fragment Classification through Visual Perspectives,â€ in <b>IEEE Transactions on Multimedia</b>, 2024. (Corresponding Author)</li>
  <li>&thinsp;<b>K. Wu</b>, Q. Liu, and X. Zhang, â€œFocal Stack Image Compression Based on Basis-Quadtree Representation,â€ in <b>IEEE Transactions on Multimedia</b>, 25:3975-3988, 2023.</li>
  <li>&thinsp;<b>K. Wu</b>, Q. Liu, Y. Yang, and X. Zhang, â€œGaussian-Wiener Representation and Hierarchical Coding Scheme for Focal Stack Images,â€ in <b>IEEE Transactions on Circuits and Systems for Video Technology</b>, 32(2):523-537, 2022.</li>
  <li>&thinsp;<b>K. Wu</b>, Z. Li, Y. Yang, and Q. Liu, â€œDeep Video Compression based on Long-range Temporal Context Learning,â€ in Computer Vision and Image Understanding, 248(2024): 104127.</li>  
  <li>&thinsp;X. Yu, <b>K. Wu</b><font color=Blue>*</font>, Y. Yang, and Q. Liu, â€œWaRENet: A Novel Urban Waterlogging Risk Evaluation Network,â€ in ACM Transactions on Multimedia Computing, Communications, and Applications, 2024, 20(7):1â€“28. (Equal Contribution)</li>
  <li>&thinsp;<b>K. Wu</b>, Q. Liu, K. Yap, and Y. Yang, â€œMultifocal Multiview Imaging and Data Compression based on Angular-Focal-Spatial Representation,â€ in Optics Letters, 2024.</li>
  <li>&thinsp;<b>K. Wu</b>, Q. Liu, K. Yap, and Y. Yang, â€œHigh Dimensional Optical Data Varifocal Multiview Imaging, Compression and Evaluation,â€ in Optics Express, 2023.</li>
  <li>&thinsp;<b>K. Wu</b>, Q. Liu, Y. Wang, and Y. Yang, â€œEnd-to-end Varifocal Multiview Images Coding Framework from Data Acquisition End to Vision Application End,â€ in Optics Express, 31(7): 11659-11679, 2023.</li>
  <li>&thinsp;T. Liu, <b>K. Wu</b><font color=Blue>*</font>, Y. Wang, W. Liu, K. Yap, and L. Chau, â€œBitstream corrupted Video Recovery: A Novel Benchmark Dataset and Method,â€ NeurIPS 2023. (Equal Contribution)</li>
  <li>&thinsp;J. Gao, K. Yap, K. Wu, D. Phan, and K. Garg, "Contextual Human Object Interaction Understanding from Pre-Trained Large Language Model," ICASSP 2024, Seoul, Korea</li>
  <li>&thinsp;C. Cai, R. Zhang, J. Gao, K. Wu, K. Yap, Y. Wang, "Temporal Sentence Grounding with Temporally Global Textual Knowledge," ICME 2024, Niagra Falls, Canada</li>
  </ul>
</div>




<span class='anchor' id='honors-awards'></span>
# <span style="color:rgb(17,85,160)">Honors & Awards</span>
<!-- 
# Honors & Awards
[//]: # ğŸ† Honors & Awards
-->

- China International College Students' Innovation Competition (formerly Internet +, Gold Award)
- IET Excellence and Innovation Awards International Awards (Silver Award)
- National Postdoctoral Innovation and Entrepreneurship Competition (Bronze Award, ranked first)
- Chunhui Cup Innovation and Entrepreneurship Competition for Chinese Overseas Students (ranked first)
- IET Impact in Society Awards (Shortlist)
- Letter of Appreciation from University of Oxford


<span class='anchor' id='educations'></span>
# <span style="color:rgb(17,85,160)">Educations</span>
<!-- 
# Educations
# ğŸ“– Educations
-->

- Exchange Ph.D Student, School of Electrical and Electronic Engineering, Nanyang Technological University
- Ph.D Student, School of Electronic Information and Communications, Huazhong University of Science and Technology
- Master Student, College of Intelligent Science and Engineering, Harbin Engineering University
- Undergraduate Student, School of Mechatronic Engineering and Automation, Shanghai University


<!-- æ®µè½æ³¨é‡Š 
<span class='anchor' id='invited-talks'></span>
# Talks/Presentations
[//]: # ğŸ’¡ Talks/Presentations
[//]: ğŸ’¬
[//]: - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
[//]: - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
- Annual Conference on Neural Information Processing Systems (NeurIPS 2023), New Orleans, Louisiana, USA
- 2023 Data Compression Conference (DCC), Snowbird, UT, USA
- 2019 Data Compression Conference (DCC), Snowbird, UT, USA
-->


<span class='anchor' id='students'></span>
# <span style="color:rgb(17,85,160)">Students</span>
<!-- 
# Students
-->

I'm honored to have participated in the supervision of these excellent students: 
- J. Liang, Intern Student, Huazhong University of Science and Technology (LLMs on multimedia understanding)
- F. Li, Master Student, Huazhong University of Science and Technology (LLMs on Byte-domain  understanding)
- C. Zhang, Ph.D Student, Huazhong University of Science and Technology (LLMs on signal processing)
- R. Wang, Ph.D Student, Harbin Engineering University (LLMs on fine-grained recognition)
- S. Wang, Ph.D Student, Harbin Engineering University (LLMs on SAR image anomaly detection)
<!-- æ®µè½æ³¨é‡Š - R. Yan, Undergraduate Student, Xiamen University (LLMs on signal analytics)  -->
- J. Gao, Ph.D Student, Nanyang Technological University (LLMs on HOI)
- W. Liu, Ph.D Student, Nanyang Technological University (Gen-AI on image restoration)
- T. Liu, Ph.D Student, Nanyang Technological University (Gen-AI on image restoration)
- C. Cai, Ph.D, National University of Singapore (Scientist, NUS, LLMs on remote sensing)
  
